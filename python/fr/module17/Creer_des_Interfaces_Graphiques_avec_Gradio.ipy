{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_XJcxqx22uj"
      },
      "source": [
        "# Utiliser `Gradio` pour créer et déployer des applications sympathiques avec Interface Graphique rapidement.\n",
        "`Gradio` permet de construire en quelques lignes de code Python, une démo que vous pouvez partager avec le monde.\n",
        "Il prend en charge de nombreux types de composants, tels que les images, les DataFrame, les vidéos ou les étiquettes.\n",
        "\n",
        "Consultez la bibliothèque sur [github](https://github.com/gradio-app/gradio-UI) et voir le [guide de démarrage rapide](https://gradio.app/getting_started.html) pour plus de demos.\n",
        "\n",
        "##### Instructeur: Joan Mouba, Dr.-Ing. en Informatique\n",
        "L'utilisation de ce fichier est sous la license GPL.\n",
        "Vous pouvez utiliser, modifier et redistribuer librement.\n",
        "\n",
        "Nous serons reconnaissant si vous mentionnez l'auteur et/ou la référence source du Notebook:\n",
        "[https://bit.ly/3skCdlO](https://colab.research.google.com/drive/1ajrZfkap-L-ZnXBkfKyQmSdi5tgBHZ-Z?usp=sharing)\n",
        "\n",
        "LinkedIn: [![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&style=social&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/joanmouba/) - https://www.linkedin.com/in/joanmouba/\n",
        "\n",
        "Web: [https://epignosiscenter.com](https://epignosiscenter.com)\n",
        "\n",
        "Courriel: joan.mouba@epignosiscenter.com\n",
        "\n",
        "Canal Youtube: [![YouTube](https://img.shields.io/youtube/channel/subscribers/UCjqWeYtZ82DBan-vhFzkTog)](https://www.youtube.com/channel/UCjqWeYtZ82DBan-vhFzkTog)\n",
        "\n",
        "Répertoire GitHub:[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&style=social&logo=github&logoColor=white)](https://github.com/JoanMouba)  \n",
        "\n",
        "Merci de me laisser un avis sur Google: [Je laisse mon avis sur la formation](https://g.page/r/CRFbaxcVvqo9EAI/review)\n",
        "\n",
        "Dernière mise à jour: 05.12.2023 par Joan Mouba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbcRKXEYuNtu"
      },
      "source": [
        "## Agenda\n",
        "1.  Qu'est-ce que Gradio?\n",
        "2. Interface Gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu1dYN02uU3B"
      },
      "source": [
        "## Installer Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AC9YVkLuXct",
        "outputId": "74db368a-9d34-4069-ea15-611d77bb1ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed kaleido-0.2.1\n",
            "Collecting cohere\n",
            "  Downloading cohere-4.39-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.1)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.11.17)\n",
            "Installing collected packages: importlib_metadata, fastavro, backoff, cohere\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cohere-4.39 fastavro-1.9.2 importlib_metadata-6.11.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.6.1 typing-extensions-4.9.0\n",
            "Collecting typing-extensions<4.6.0,>=1.3.0\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "openai 1.6.1 requires typing-extensions<5,>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.5.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.1/305.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# À cause de problèmes de compatibilités dans Google Colab.\n",
        "# Nous avons installer quelques modules en plus\n",
        "!pip install tiktoken\n",
        "!pip install kaleido\n",
        "!pip install cohere\n",
        "!pip install openai\n",
        "!pip install 'typing-extensions>=1.3.0,<4.6.0'\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUHtJ20jYqd9"
      },
      "source": [
        "## Demo basique avec 1 Entrée et 1 Sortie\n",
        "Commencerons par une fonction de base qui accueille un nom en entrée et renvoie une salutation personnalisée."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qtlFLbke2Sob",
        "outputId": "6fd1bc4c-ad03-49ca-b5b4-63ef7b3cd004"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Salut Tout le monde!!'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def salut(nom):\n",
        "  return \"Salut \" + nom + \"!\"\n",
        "\n",
        "salut(\"Tout le monde!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R06dbZZaYJDq"
      },
      "source": [
        "Enveloppons cette fonction dans une interface Gradio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "e200MmBU2aLT",
        "outputId": "756f3db7-a943-402b-837d-73f751065319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://24ccbedaea920a8f14.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://24ccbedaea920a8f14.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "demo = gr.Interface(fn=salut, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch(share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9bFfiyn_eXh"
      },
      "source": [
        "## Demo avec plusieurs Entrées et plusieurs Sortie\n",
        "Créeons une application qui prends plusieurs types d'entrées, et renvoie plusieurs types d'informations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GUb7SjNzekm"
      },
      "source": [
        "Utilisons les éléments graphiques:\n",
        " graphique de texte plus élaboré:\n",
        "\n",
        "*   Entrées: text, checkbox, slider (`gradio.Slider(min, max)`)\n",
        "*   Sorties: text, number\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogTj5ckZ0B8c"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def salut_elabore(nom, cestLeMatin, temperature):\n",
        "    #salutation = \"Bonjour\" if cestLeMatin else \"Bonsoir\"\n",
        "\n",
        "    if cestLeMatin:\n",
        "        salutation = \"Bonjour\"\n",
        "    else:\n",
        "        salutation = \"Bonsoir\"\n",
        "\n",
        "    emotion = \"C'est froid!\" if temperature<15 else \"Il fait bon\"\n",
        "\n",
        "    phrase = f\"{salutation} {nom}!\\n {emotion} avec {temperature} degrés!\"\n",
        "\n",
        "    return phrase, temperature\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=salut_elabore,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=2, placeholder=\"Rentrez votre nom ici ...\" ),\n",
        "        gr.Checkbox(label=\"Est-ce le matin?\"),\n",
        "        gr.Slider(0,40)\n",
        "    ],\n",
        "    outputs=[\"text\", \"number\"],\n",
        ")\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Mn6mazFZ_B"
      },
      "source": [
        "## Demo avec une image en Entrée et une image transformée en Sortie\n",
        "Créeons une application qui transforme une image en une image ayant un ton sépia.\n",
        "Le sépia est une couleur brun-rougeâtre, nommée d'après le riche pigment brun dérivé du sac d'encre de la seiche commune Sepia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M7pJOroU8ya"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAQ2vTD6EM43"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "def sepia(input_img):\n",
        "    filtre_sepia = np.array([\n",
        "        [0.393, 0.769, 0.189],\n",
        "        [0.349, 0.686, 0.168],\n",
        "        [0.272, 0.534, 0.131]\n",
        "    ])\n",
        "    sepia_img = input_img.dot(filtre_sepia.T)\n",
        "    sepia_img /= sepia_img.max()\n",
        "    return sepia_img\n",
        "\n",
        "demo = gr.Interface(fn=sepia, inputs=gr.Image(), outputs=\"image\")\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zE6qiRsU-H1"
      },
      "source": [
        "## Demo en créant une interface personnalisée\n",
        "Créeons une application avec plus de contrôle sur la position de nos éléments graphiques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25BqYNkHUaLV"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def salut(nom):\n",
        "  return \"Salut \" + nom + \"!\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    nom = gr.Textbox(label=\"Nom\")\n",
        "    sortie = gr.Textbox(label=\"Affichage\")\n",
        "    salut_btn = gr.LogoutButton(\"Salutations\")\n",
        "    salut_btn.click(fn=salut, inputs=nom, outputs=sortie)\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJHleAt0X7gh"
      },
      "source": [
        "## Exercice 1\n",
        "Créez une application Calculatrice\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1KvWLp8YdYQ"
      },
      "source": [
        "### Votre solution ici"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Z9cDPyYKgk"
      },
      "outputs": [],
      "source": [
        "# Votre code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg5Kw97fYSrg"
      },
      "source": [
        "### Ma proposition de solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoXxTpnRYN4_"
      },
      "outputs": [],
      "source": [
        "# Ma solution\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def calculatrice(op1, operation, op2):\n",
        "    if operation == \"+\":\n",
        "        return op1 + op2\n",
        "    elif operation == \"-\":\n",
        "        return op1 - op2\n",
        "    elif operation == \"*\":\n",
        "        return op1 * op2\n",
        "    elif operation == \"/ Division\":\n",
        "        return op1 / op2\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=calculatrice,\n",
        "    inputs=[\n",
        "        \"number\",\n",
        "        gr.Radio([\"+\", \"-\", \"*\", \"/\"]),\n",
        "        \"number\"\n",
        "\n",
        "     ],\n",
        "     outputs=\"number\",\n",
        "    examples=[\n",
        "        [10, \"+\", 5],\n",
        "        [4, \"-\", 3],\n",
        "    ],\n",
        "    title=\"Calculatrice Formidable\",\n",
        "    description=\"Amusez-vous bien!\",\n",
        ")\n",
        "\n",
        "demo.launch(share=True, debug=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5UnbD7pY_CQ"
      },
      "source": [
        "## Exercice 2\n",
        "Créez une application de Calcul d'intérêts composés:\n",
        "*   Avec Python et Gradio\n",
        "*   Partagez avec 5 amis dans les 3 prochains jours  \n",
        "*   Notez leurs feedbacks et améliorez en continue.\n",
        "*   Laissez un commentaire sur ce que vous avez ressenti et vécu lors de ce processus.\n",
        "\n",
        "Liens utiles et inspirants:\n",
        "\n",
        "*   https://en.wikipedia.org/wiki/Compound_interest\n",
        "\n",
        "*   https://www.gerezmieuxvotreargent.ca/calculatrices/calculatrice-interets-composes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qaxDAQcYpAL"
      },
      "source": [
        "## Conclusion\n",
        "Avec Gradio\n",
        "\n",
        "*   Créer vos démos\n",
        "*   Partagez votre créativité avec le monde\n",
        "*   Déployez facilement les produits de votre pensée\n",
        "*   Tout en Python!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQheRaw5YVTL"
      },
      "source": [
        "C'est tout pour aujourd'hui ! Allez-y et ouvrez le lien de partage de votre application dans un nouvel onglet.\n",
        "Consultez notre page pour des formations et des démos plus complexes: [Epignosis Center](https://epignosiscenter.com) .\n",
        "\n",
        "Merci de me laisser un avis sur Google: [Je laisse mon avis sur la formation](https://g.page/r/CRFbaxcVvqo9EAI/review)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
